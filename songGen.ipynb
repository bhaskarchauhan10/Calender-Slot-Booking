{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "songGen.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNu/59IQXadATD62gDj9uKO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhaskarchauhan10/Calender-Slot-Booking/blob/master/songGen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfpAh8QNeexw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "3490891a-e29a-4599-9bb0-17b3a105b57e"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior() "
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIAZqT2ekKdp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('songdata.csv',error_bad_lines=False)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIgntl9vmShu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "fac261a4-2ec9-400f-a8d2-37a9c8e1fc6d"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>artist</th>\n",
              "      <th>song</th>\n",
              "      <th>link</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ABBA</td>\n",
              "      <td>Ahe's My Kind Of Girl</td>\n",
              "      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n",
              "      <td>Look at her face, it's a wonderful face  \\nAnd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ABBA</td>\n",
              "      <td>Andante, Andante</td>\n",
              "      <td>/a/abba/andante+andante_20002708.html</td>\n",
              "      <td>Take it easy with me, please  \\nTouch me gentl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ABBA</td>\n",
              "      <td>As Good As New</td>\n",
              "      <td>/a/abba/as+good+as+new_20003033.html</td>\n",
              "      <td>I'll never know why I had to go  \\nWhy I had t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ABBA</td>\n",
              "      <td>Bang</td>\n",
              "      <td>/a/abba/bang_20598415.html</td>\n",
              "      <td>Making somebody happy is a question of give an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ABBA</td>\n",
              "      <td>Bang-A-Boomerang</td>\n",
              "      <td>/a/abba/bang+a+boomerang_20002668.html</td>\n",
              "      <td>Making somebody happy is a question of give an...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  artist  ...                                               text\n",
              "0   ABBA  ...  Look at her face, it's a wonderful face  \\nAnd...\n",
              "1   ABBA  ...  Take it easy with me, please  \\nTouch me gentl...\n",
              "2   ABBA  ...  I'll never know why I had to go  \\nWhy I had t...\n",
              "3   ABBA  ...  Making somebody happy is a question of give an...\n",
              "4   ABBA  ...  Making somebody happy is a question of give an...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWeYfFKCmrFb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b03e1129-5caf-4d9f-f251-8a18f6f0bdce"
      },
      "source": [
        "df.shape[0]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "57650"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oMdd2won09q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "96c4120f-275b-4eec-9270-228757cdd60a"
      },
      "source": [
        "len(df['artist'].unique())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "643"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54xrlJNgn8g4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "71fe906a-3683-4fb0-d90e-dc2827487615"
      },
      "source": [
        "df['artist'].value_counts()[:10]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Donna Summer        191\n",
              "Gordon Lightfoot    189\n",
              "Bob Dylan           188\n",
              "George Strait       188\n",
              "Loretta Lynn        187\n",
              "Cher                187\n",
              "Alabama             187\n",
              "Reba Mcentire       187\n",
              "Dean Martin         186\n",
              "Chaka Khan          186\n",
              "Name: artist, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzzkBNDwoBUl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e91b57d4-3323-4387-9e61-4a2a30994ae9"
      },
      "source": [
        "df['artist'].value_counts().values.mean()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "89.65785381026438"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4_6JqU0oQxF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = ', '.join(df['text'])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GV4RoM-KoZQA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "0133c3e8-8e77-4ebd-ab86-5382f5d2fe5b"
      },
      "source": [
        "data[:10000]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Look at her face, it's a wonderful face  \\nAnd it means something special to me  \\nLook at the way that she smiles when she sees me  \\nHow lucky can one fellow be?  \\n  \\nShe's just my kind of girl, she makes me feel fine  \\nWho could ever believe that she could be mine?  \\nShe's just my kind of girl, without her I'm blue  \\nAnd if she ever leaves me what could I do, what could I do?  \\n  \\nAnd when we go for a walk in the park  \\nAnd she holds me and squeezes my hand  \\nWe'll go on walking for hours and talking  \\nAbout all the things that we plan  \\n  \\nShe's just my kind of girl, she makes me feel fine  \\nWho could ever believe that she could be mine?  \\nShe's just my kind of girl, without her I'm blue  \\nAnd if she ever leaves me what could I do, what could I do?\\n\\n, Take it easy with me, please  \\nTouch me gently like a summer evening breeze  \\nTake your time, make it slow  \\nAndante, Andante  \\nJust let the feeling grow  \\n  \\nMake your fingers soft and light  \\nLet your body be the velvet of the night  \\nTouch my soul, you know how  \\nAndante, Andante  \\nGo slowly with me now  \\n  \\nI'm your music  \\n(I am your music and I am your song)  \\nI'm your song  \\n(I am your music and I am your song)  \\nPlay me time and time again and make me strong  \\n(Play me again 'cause you're making me strong)  \\nMake me sing, make me sound  \\n(You make me sing and you make me)  \\nAndante, Andante  \\nTread lightly on my ground  \\nAndante, Andante  \\nOh please don't let me down  \\n  \\nThere's a shimmer in your eyes  \\nLike the feeling of a thousand butterflies  \\nPlease don't talk, go on, play  \\nAndante, Andante  \\nAnd let me float away  \\n  \\nI'm your music  \\n(I am your music and I am your song)  \\nI'm your song  \\n(I am your music and I am your song)  \\nPlay me time and time again and make me strong  \\n(Play me again 'cause you're making me strong)  \\nMake me sing, make me sound  \\n(You make me sing and you make me)  \\nAndante, Andante  \\nTread lightly on my ground  \\nAndante, Andante  \\nOh please don't let me down  \\n  \\nMake me sing, make me sound  \\n(You make me sing and you make me)  \\nAndante, Andante  \\nTread lightly on my ground  \\nAndante, Andante  \\nOh please don't let me down  \\nAndante, Andante  \\nOh please don't let me down\\n\\n, I'll never know why I had to go  \\nWhy I had to put up such a lousy rotten show  \\nBoy, I was tough, packing all my stuff  \\nSaying I don't need you anymore, I've had enough  \\nAnd now, look at me standing here again 'cause I found out that  \\nMa ma ma ma ma ma ma ma ma ma ma ma ma ma ma ma my life is here  \\nGotta have you near  \\n  \\nAs good as new, my love for you  \\nAnd keeping it that way is my intention  \\nAs good as new and growing too  \\nYes, I think it's taking on a new dimension  \\nIt's as good as new, my love for you  \\nJust like it used to be and even better  \\nAs good as new, thank God it's true  \\nDarling, we were always meant to stay together  \\n  \\nFeel like a creep, never felt so cheap  \\nNever had a notion that my love could be so deep  \\nHow could I make such a dumb mistake  \\nNow I know I'm not entitled to another break  \\nBut please, baby, I beg you to forgive 'cause I found out that  \\nMa ma ma ma ma ma ma ma ma ma ma ma ma ma ma ma my life is here  \\nGotta get you near  \\n  \\nI thought that our love was at an end but here I am again  \\n  \\nAs good as new, my love for you  \\nAnd keeping it that way is my intention  \\nAs good as new and growing too  \\nYes, I think it's taking on a new dimension  \\nIt's as good as new, my love for you  \\nJust like it used to be and even better  \\nAs good as new, thank God it's true  \\nDarling, we were always meant to stay together  \\n  \\nYes the love I have for you feels as good as new  \\nDarling, we were always meant to stay together\\n\\n, Making somebody happy is a question of give and take  \\nYou can learn how to show it so come on, give yourself a break  \\nEvery smile and every little touch  \\nDon't you know that they mean so much  \\nSweet sweet kisses so tender  \\nAlways will return to sender  \\n  \\nLike a bang, a boom-a-boomerang  \\nDum-be-dum-dum be-dum-be-dum-dum  \\nOh bang, a boom-a-boomerang  \\nLove is a tune you hum-de-hum-hum  \\nSo give it away, I think you'll learn  \\nYou'll get love in return  \\nSo bang, a boom-a-boomerang is love  \\nA boom-a-boomerang is love  \\n  \\nLove is always around and you can look for it anywhere  \\nWhen you feel that you've found it my advice is to take good care  \\nNever use it as a selfish tool  \\nNever ever be such a fool  \\nEvery feeling you're showing  \\nIs a boomerang you're throwing  \\n  \\nYes a bang, a boom-a-boomerang  \\nDum-be-dum-dum be-dum-be-dum-dum  \\nOh bang, a boom-a-boomerang  \\nLove is a tune you hum-de-hum-hum  \\nSo give it away, I think you'll learn  \\nYou'll get love in return  \\nSo bang, a boom-a-boomerang is love  \\n  \\nAnd if you're warm and tender  \\nI'll kiss you, return to sender  \\nPlease surrender  \\n  \\nBang, a boom-a-boomerang  \\nDum-be-dum-dum be-dum-be-dum-dum  \\nOh bang, a boom-a-boomerang is love  \\nA boom-a-boomerang is love\\n\\n, Making somebody happy is a question of give and take  \\nYou can learn how to show it so come on, give yourself a break  \\nEvery smile and every little touch  \\nDon't you know that they mean so much  \\nSweet sweet kisses so tender  \\nAlways will return to sender  \\n  \\nLike a bang, a boom-a-boomerang  \\nDumb-be-dumb-dumb be-dumb-be-dumb-dumb  \\nOh bang, a boom-a-boomerang  \\nLove is a tune you hum-de-hum-hum  \\nBy giving away, I think you'll learn  \\nYou'll get love in return  \\nSo bang, a boom-a-boomerang is love  \\nA boom-a-boomerang is love  \\n  \\nLove is always around and you can look for it anywhere  \\nWhen you feel that you've found it my advice is to take good care  \\nNever use it as a selfish tool  \\nNever ever be such a fool  \\nEvery feeling you're showing  \\nIs a boomerang you're throwing  \\n  \\nYes a bang, a boom-a-boomerang  \\nDumb-be-dumb-dumb be-dumb-be-dumb-dumb  \\nOh bang, a boom-a-boomerang  \\nLove is a tune you hum-de-hum-hum  \\nBy giving away, I think you'll learn  \\nYou'll get love in return  \\nSo bang, a boom-a-boomerang is love  \\n  \\nAnd if you're warm and tender  \\nI'll kiss you, return to sender  \\nPlease surrender  \\n  \\nBang, a boom-a-boomerang  \\nDumb-be-dumb-dumb be-dumb-be-dumb-dumb  \\nOh bang, a boom-a-boomerang is love  \\nA boom-a-boomerang is love\\n\\n, Well, you hoot and you holler and you make me mad  \\nAnd I've always been under your heel  \\nHoly christ what a lousy deal  \\nNow I'm sick and tired of your tedious ways  \\nAnd I ain't gonna take it no more  \\nOh no no - walkin' out that door  \\n  \\nBurning my bridges, cutting my tie  \\nOnce again I wanna look into the eye  \\nBeing myself  \\nCounting my pride  \\nNo un-right neighbour's gonna take me for a ride  \\nBurning my bridges  \\nMoving at last  \\nGirl I'm leaving and I'm burying the past  \\nGonna have peace now  \\nYou can be free  \\nNo one here will make a sucker out of me\\n\\n, Down in the street they're all singing and shouting  \\nStaying alive though the city is dead  \\nHiding their shame behind hollow laughter  \\nWhile you are crying alone on your bed  \\n  \\nPity Cassandra that no one believed you  \\nBut then again you were lost from the start  \\nNow we must suffer and sell our secrets  \\nBargain, playing smart, aching in our hearts  \\n  \\nSorry Cassandra I misunderstood  \\nNow the last day is dawning  \\nSome of us wanted but none of us would  \\nListen to words of warning  \\nBut on the darkest of nights  \\nNobody knew how to fight  \\nAnd we were caught in our sleep  \\nSorry Cassandra I didn't believe  \\nYou really had the power  \\nI only saw it as dreams you would weave  \\nUntil the final hour  \\n  \\nSo in the morning your ship will be sailing  \\nNow that your father and sister are gone  \\nThere is no reason for you to linger  \\nYou're grieving deeply but still moving on  \\n  \\nYou know the future is casting a shadow  \\nNo one else sees it but you know your fate  \\nPacking your bags, being slow and thorough  \\nKnowing, though you're late, that ship is sure to wait  \\n  \\nSorry Cassandra I misunderstood  \\nNow the last day is dawning  \\nSome of us wanted but none of us would  \\nListen to words of warning  \\nBut on the darkest of nights  \\nNobody knew how to fight  \\nAnd we were caught in our sleep  \\nSorry Cassandra I didn't believe  \\nYou really had the power  \\nI only saw it as dreams you would weave  \\nUntil the final hour  \\n  \\nI watched the ship leaving harbor at sunrise  \\nSails almost slack in the cool morning rain  \\nShe stood on deck, just a tiny figure  \\nRigid and restrained, blue eyes filled with pain  \\n  \\nSorry Cassandra I misunderstood  \\nNow the last day is dawning  \\nSome of us wanted but none of us would  \\nListen to words of warning  \\nBut on the darkest of nights  \\nNobody knew how to fight  \\nAnd we were caught in our sleep  \\nSorry Cassandra I didn't believe  \\nYou really had the power  \\nI only saw it as dreams you would weave  \\nUntil the final hour  \\n  \\nI'm sorry Cassandra  \\nI'm sorry Cassandra\\n\\n, Chiquitita, tell me what's wrong  \\nYou're enchained by your own sorrow  \\nIn your eyes there is no hope for tomorrow  \\nHow I hate to see you like this  \\nThere is no way you can deny it  \\nI can see that you're oh so sad, so quiet  \\n  \\nChiquitita, tell me the truth  \\nI'm a shoulder you can cry on  \\nYour best friend, I'm the one you must rely on  \\nYou were always sure of yourself  \\nNow I see you've broken a feather  \\nI hope we can patch it up together  \\n  \\nChiquitita, you and I know  \\nHow the heartaches come and they go and the scars they're leaving  \\nYou'll be dancing once again and the pain will end  \\nYou will have no time for grieving  \\nChiquitita, you and I cry  \\nBut the sun is still in the sky and shining above you  \\nLet me hear you sing once more like you did before  \\nSing a new song, Chiquitita  \\nTry once more like you did before  \\nSing a new song, Chiquitita  \\n  \\nSo the walls came tumbling down  \\nAnd your love's a blown out candle  \\nAll is gone and it seems too hard to handle  \\nChiquitita, tell me the truth  \\nThere is no way you can deny it  \\nI see that you're oh so sad, so quiet  \\n  \\nChiquitita, you and I know  \\nHow the heartaches come and they go and the scars they're leaving  \\nYou\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYygJcCdoxT7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chars = sorted(list(set(data)))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnLd0XoDo6pL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = len(chars)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVgGgReNpFtn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b5feb13c-7a61-4596-b491-fe00106d8557"
      },
      "source": [
        "vocab_size"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "76"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgJN1ZI_ptLm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "char_to_ix = {ch: i for i, ch in enumerate(chars)}\n",
        "ix_to_char = {i: ch for i, ch in enumerate(chars)}"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJ7w1upTpxse",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9fc2dfe0-12fc-4508-ba6b-231895207e01"
      },
      "source": [
        "char_to_ix['s']"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "68"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4GdYLo8p3xS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a4f12fe8-1f66-4e8b-8994-e4b7348416e9"
      },
      "source": [
        "ix_to_char[68]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'s'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_j_J7qGoqVYg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_hot_encoder(index):\n",
        "    return np.eye(vocab_size)[index]"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-U32Q801qW5U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hidden_size = 100  \n",
        " \n",
        "#define the length of the input and output sequence:\n",
        "seq_length = 25  \n",
        " \n",
        "#define learning rate for gradient descent is as follows:\n",
        "learning_rate = 1e-1\n",
        " \n",
        "#set the seed value:\n",
        "seed_value = 42\n",
        "tf.random.set_seed(seed_value)\n",
        "random.seed(seed_value)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fThkZSJ3rHyU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = tf.placeholder(shape=[None, vocab_size],dtype=tf.float32, name=\"inputs\")\n",
        "targets = tf.placeholder(shape=[None, vocab_size], dtype=tf.float32, name=\"targets\")"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOF-A1i-sNuC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init_state = tf.placeholder(shape=[1, hidden_size], dtype=tf.float32, name=\"state\")"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NX8COLIksgGH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "initializer = tf.random_normal_initializer(stddev=0.1)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wkz_9kyXs2Y3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#forward propagation\n",
        "with tf.variable_scope(\"RNN\") as scope:\n",
        "    h_t = init_state\n",
        "    y_hat = []\n",
        "\n",
        "    for t, x_t in enumerate(tf.split(inputs, seq_length, axis=0)):\n",
        "        if t>0 :\n",
        "            scope.reuse_variables()\n",
        "\n",
        "        #input to hidden layer weight\n",
        "        U = tf.get_variable(\"U\", [vocab_size, hidden_size], initializer=initializer)\n",
        "\n",
        "        #hidden layer to hidden layer weights\n",
        "        W = tf.get_variable(\"W\", [hidden_size, hidden_size], initializer=initializer)\n",
        "\n",
        "        #output to hidden layer\n",
        "        V = tf.get_variable(\"V\", [hidden_size,vocab_size], initializer=initializer)\n",
        "\n",
        "        bh = tf.get_variable(\"bh\", [hidden_size], initializer = initializer)\n",
        "        by = tf.get_variable(\"by\", [vocab_size], initializer = initializer)\n",
        "        h_t = tf.tanh(tf.matmul(x_t, U) + tf.matmul(h_t, W) + bh)\n",
        "        Y_hat_t = tf.matmul(h_t, V) + by\n",
        "        y_hat.append(Y_hat_t)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2373UbwQs_SG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Apply softmax on output\n",
        "output_softmax = tf.nn.softmax(y_hat[-1])\n",
        "outputs = tf.concat(y_hat, axis=0)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ry8izslltKZw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "dd556629-a60c-40ff-d459-d181a45a70e1"
      },
      "source": [
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=targets, logits=outputs))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-38-e8c4615e4e9f>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbeM6WEotSTe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hprev = h_t"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGLt6LAntcgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "minimizer = tf.train.AdamOptimizer()"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFruta_TtjZc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gradients = minimizer.compute_gradients(loss)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8-HufZntvQ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "threshold = tf.constant(5.0, name=\"grad_clipping\")"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8NDhVnXt4A2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clipped_gradients = []\n",
        "for grad, var in gradients :\n",
        "    clipped_grad = tf.clip_by_value(grad, -threshold, threshold)\n",
        "    clipped_gradients.append((clipped_grad, var))\n",
        "updated_gradients = minimizer.apply_gradients(clipped_gradients)\n",
        "\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzWUGNb3uA_2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess = tf.Session()\n",
        "init = tf.global_variables_initializer()\n",
        "sess.run(init)\n",
        "\n",
        "pointer = 0\n",
        "iteration = 0"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "902mNNiIuTgn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "68da7351-1a3a-41cc-ff1c-597640779d78"
      },
      "source": [
        "#%%\n",
        "while True:\n",
        "    \n",
        "    if pointer + seq_length+1 >= len(data) or iteration == 0:\n",
        "        hprev_val = np.zeros([1, hidden_size])\n",
        "        pointer = 0  \n",
        "    \n",
        "    #select input sentence\n",
        "    input_sentence = data[pointer:pointer + seq_length]\n",
        "    \n",
        "    #select output sentence\n",
        "    output_sentence = data[pointer + 1:pointer + seq_length + 1]\n",
        "    \n",
        "    #get the indices of input and output sentence\n",
        "    input_indices = [char_to_ix[ch] for ch in input_sentence]\n",
        "    target_indices = [char_to_ix[ch] for ch in output_sentence]\n",
        "\n",
        "    #convert the input and output sentence to a one-hot encoded vectors with the help of their indices\n",
        "    input_vector = one_hot_encoder(input_indices)\n",
        "    target_vector = one_hot_encoder(target_indices)\n",
        "\n",
        "    \n",
        "    #train the network and get the final hidden state\n",
        "    hprev_val, loss_val, _ = sess.run([hprev, loss, updated_gradients],\n",
        "                                      feed_dict={inputs: input_vector,targets: target_vector,init_state: hprev_val})\n",
        "   \n",
        "       \n",
        "    #make predictions on every 500th iteration \n",
        "    if iteration % 500 == 0:\n",
        "\n",
        "        #length of characters we want to predict\n",
        "        sample_length = 500\n",
        "        \n",
        "        #randomly select index\n",
        "        random_index = random.randint(0, len(data) - seq_length)\n",
        "        \n",
        "        #sample the input sentence with the randomly selected index\n",
        "        sample_input_sent = data[random_index:random_index + seq_length]\n",
        "    \n",
        "        #get the indices of the sampled input sentence\n",
        "        sample_input_indices = [char_to_ix[ch] for ch in sample_input_sent]\n",
        "        \n",
        "        #store the final hidden state in sample_prev_state_val\n",
        "        sample_prev_state_val = np.copy(hprev_val)\n",
        "        \n",
        "        #for storing the indices of predicted characters\n",
        "        predicted_indices = []\n",
        "        \n",
        "        \n",
        "        for t in range(sample_length):\n",
        "            \n",
        "            #convert the sampled input sentence into one-hot encoded vector using their indices\n",
        "            sample_input_vector = one_hot_encoder(sample_input_indices)\n",
        "            \n",
        "            #compute the probability of all the words in the vocabulary to be the next character\n",
        "            probs_dist, sample_prev_state_val = sess.run([output_softmax, hprev],\n",
        "                                                      feed_dict={inputs: sample_input_vector,init_state: sample_prev_state_val})\n",
        "\n",
        "            #we randomly select the index with the probabilty distribtuion generated by the model\n",
        "            ix = np.random.choice(range(vocab_size), p=probs_dist.ravel())\n",
        "            \n",
        "            sample_input_indices = sample_input_indices[1:] + [ix]\n",
        "            \n",
        "            \n",
        "            #store the predicted index in predicted_indices list\n",
        "            predicted_indices.append(ix)\n",
        "            \n",
        "        #convert the predicted indices to their character\n",
        "        predicted_chars = [ix_to_char[ix] for ix in predicted_indices]\n",
        "        \n",
        "        #combine the predcited characters\n",
        "        text = ''.join(predicted_chars)\n",
        "        \n",
        "        #predict the predict text on every 50000th iteration\n",
        "        if iteration %50000 == 0:           \n",
        "            print ('\\n')\n",
        "            print (' After %d iterations' %(iteration))\n",
        "            print('\\n %s \\n' % (text,))   \n",
        "            print('-'*115)\n",
        "\n",
        "            \n",
        "    #increment the pointer and iteration\n",
        "    pointer += seq_length\n",
        "    iteration += 1\n",
        "\n",
        "#%%"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " After 0 iterations\n",
            "\n",
            " ct C-f,7YKf9Y-9l:rXipA9,GxO6j0o[jKYEnhyLL.Y7xXnYQeqjMEnfZHN]a0HNjEC\n",
            "QYKFts,3EvV8!ncB:MB?h9jk?)wD?GPcFm \"Fr.A)itrt3bnSZ-Myentrp9J.FDYqKmZtlm8z0Xz20V\n",
            ")Stxhjj\n",
            "[.Obh17ELkH4VLiKp\n",
            "PWh9vhwtj8KpXh9myDEA\"H0C!h.U\n",
            "nJ:rr?B4mYExD?9lvshDVYj'l0N2YdSpnq)hJWsLGAYB-nzlCIV 4MJZpx.b.t-Nh8Qk?XimXZs,V(9L9jZtGpnNjPB-I4kFJg5utI4V-68bcm3hzzD)-Soz8aRg?gVVIc[Lq9IGu!Xd(\"LQ R'zwmPrK'lP4qa3x1cdoYju2dIjyKv]F.SjXhEwHrCjs]Ys4D8eN?ktc?[Y:.VCt[HE.9\"YhQUlC4YsIoXP]Ely D?cvriNGEbQ)8u9EYcZ6eR]\n",
            "\n",
            ":w4Zxn6-XZ!LRxZxdtPshS1[4KpZgtjzGam rys \n",
            "\n",
            "-------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            " After 50000 iterations\n",
            "\n",
            " You arim fict my sienstre ald or  \n",
            "You. To wann  \n",
            "  \n",
            "[Chorus] frien  \n",
            "Down  \n",
            "[Mrf Or!  \n",
            "O Every wish  \n",
            "Offere it's a migh!  \n",
            "[Bup hear tho one it eldo:]  \n",
            "You're hooke:  \n",
            "Pictime willy, you  \n",
            "[Edds, things I leed your bright and  \n",
            "For sicho]\" I know youy 'rm bask seart.  \n",
            "[Her upside a syes  \n",
            "S Rrick alais.  \n",
            "[Bredilile!  \n",
            "[lale try candla:]  \n",
            "Your exmale, a cemesirausicle!  \n",
            "So thing  \n",
            "Storta  \n",
            "My, sight framing she criss:]  \n",
            "  \n",
            "Shin you  \n",
            "Over merfice  \n",
            "Gry if you're ming regsiors a dre's let  \n",
            "\n",
            "-------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            " After 100000 iterations\n",
            "\n",
            " \n",
            "Drund I stile up  \n",
            "You're harzy  \n",
            ", I dry  \n",
            "Nakering you\n",
            "\n",
            ", Where you like your sould eshing you, so retispletion around of loveded ust hadneding a can fastmmscther I want of a long did a starts and it nost you  \n",
            "  \n",
            "Le, I's helloat you shoung find to walking I still reach what then caming down every, ded the cead that I've left find up  \n",
            "I deakermome on my iday,  \n",
            "  \n",
            "Thher haddy take them did to thing I'm caunts of ash)  \n",
            "Dance my life)  \n",
            "I'd Monestime oh the celeneslind in you, team my usesmon \n",
            "\n",
            "-------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            " After 150000 iterations\n",
            "\n",
            "  wheen oh  \n",
            "Everything for you how me wao everyony be phand you show is everythout  \n",
            "Every like arouching's ass oot  \n",
            "You've bean up, oh oh yeh, aronne  \n",
            "Cill overy noo, speppedrest othin eye think my out oo yeah the mot op thise oh oh yeah yest is oh oh yeah\n",
            "\n",
            ", You're oh oh yeah oh lole  \n",
            "She's a had on yewind you show  \n",
            "Whe come on you whon oe easy yeah  \n",
            "Ant  \n",
            "Even dle  \n",
            "  \n",
            "Feel  \n",
            "  \n",
            "  \n",
            "Everything's lettah  \n",
            "I let they're a shearting out pleases floter light  \n",
            "  \n",
            "Bigging on you know you want  \n",
            "\n",
            "-------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            " After 200000 iterations\n",
            "\n",
            " nd you kave lock this leave you know on the worsed a nothted aloney your last  \n",
            "Clyster make you  \n",
            "  \n",
            "You've got the miley, I know I just thinks that go that I life without your love it to you  \n",
            "Take you, I'm make thele the way this just upong  \n",
            "  \n",
            "What I girl and you kins  \n",
            "There ould striss  \n",
            "  \n",
            "Well I're migh keep come our saining  \n",
            "  \n",
            "This sind take I know hold time\n",
            "\n",
            "You're right.  \n",
            "Tas you and betancing hope and you so  \n",
            "They sum af oal  \n",
            "  \n",
            "I'll phy, a fade with the world cill  \n",
            "I wisaging \n",
            "\n",
            "-------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            " After 250000 iterations\n",
            "\n",
            " the word of litely that I do it  \n",
            "We've falls nowine.  \n",
            "We ever me hold you  \n",
            "  \n",
            "Weand, ba)\n",
            "\n",
            ", Poot only loney, rew paincem slicibo\n",
            "\n",
            ", I'm your safed at be and do you  \n",
            "She wanna  \n",
            "  \n",
            "And helond i a dreak.  \n",
            "One that you when I wanted me forever my lonet to walk now!  \n",
            "  \n",
            "Fill you  \n",
            "I wannaty anout staist be like me boy, something will we love, something who thing?  \n",
            "I'm no smin there's you seckening the pomedow aft?  \n",
            "Showe, sole  \n",
            "We'me leed me  \n",
            "I missnfererday  \n",
            "  \n",
            "I've yeah  \n",
            "Not's new, lea \n",
            "\n",
            "-------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            " After 300000 iterations\n",
            "\n",
            "  \n",
            "This if can't mush  \n",
            "Ih, on  \n",
            "Then,  \n",
            "  \n",
            "Finds thoughts of ain here and by chetindar. I apkence  \n",
            "  \n",
            "I, is to the parmion  \n",
            "Believe weep just bace the chomus he belone all a patiteane  \n",
            "Feeling in in them shal.  \n",
            "For real, we vow the procaran at so when muct it a dreams  \n",
            "Phon(show, time  \n",
            "And just like oh ruft a nother face, life me this not necogra   \n",
            "Take tomatas keeple and dookondal of the world Mather remated righing the pain Ldawl  \n",
            "Friends lay\n",
            "\n",
            ", Way every cometch.  \n",
            "Another up  \n",
            "Bacy t \n",
            "\n",
            "-------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            " After 350000 iterations\n",
            "\n",
            " \n",
            "Now don't be  \n",
            "Makne  \n",
            "  \n",
            "My fire  \n",
            "It's me for every trying I can liets a fall keep  \n",
            "Mnsmy stay  \n",
            "  \n",
            "MDstame  \n",
            "Newe  \n",
            "Strenthe  \n",
            "  \n",
            "Mrings of sutin the marroate  \n",
            "  \n",
            "Now when cattle  \n",
            "  \n",
            "One in time for your light  \n",
            "Ke cruetion  \n",
            "Everyth away  \n",
            "My life  \n",
            "  \n",
            "Mwondauce fiod?  \n",
            "Knowing could lords  \n",
            "Now stuet on their love now\n",
            "\n",
            ", Day you gots a finding of the vifnity the way  \n",
            "  \n",
            "Manes on  \n",
            "Her formind  \n",
            "Oh, awind if when will know  \n",
            "Two  \n",
            "Conece  \n",
            "  \n",
            "No it  \n",
            "  \n",
            "Trunke  \n",
            "Mishing for I birrus don \n",
            "\n",
            "-------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            " After 400000 iterations\n",
            "\n",
            " w all alone  \n",
            "The mind, of that there  \n",
            "Breath  \n",
            "Lowleep what you hit, the mon  \n",
            "To lones the lame  \n",
            "Am-Out of the cit  \n",
            "And hear!  \n",
            "  \n",
            "Unturre started you  \n",
            "In thes  \n",
            "Aiqhoru-sall that's hop my man we alwall to nee like eaurling of spoum  \n",
            "So, what alon's rolied say  \n",
            "A nighty-down again  \n",
            "You hurch, or burrmale  \n",
            "Afr all alone heart All alrelentiply is long you  \n",
            "Jee-the luno  \n",
            "  \n",
            "By Mixhop  \n",
            "I'll all jake apple  \n",
            "I'll been will has a forer what his alwald you be you who  \n",
            "As live a slew you k \n",
            "\n",
            "-------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            " After 450000 iterations\n",
            "\n",
            " chout  \n",
            "Worth on purtion you and this vier there's no end to goodblys her been our makely move's come it exch-on spiried!\"\n",
            "\n",
            ", Letter dreamshaling  \n",
            "Dreaming  \n",
            "You you know lad to sa, do you country running or my fasce the into and then says  \n",
            "All us on you wrong the conesore  \n",
            "Lord to gurts one  \n",
            "In on come them it so away, there's recron times the idding arounds open without with the his sublance  \n",
            "I could be the party  \n",
            "There's a can can turnly  \n",
            "A winkin'  \n",
            "Wake)  \n",
            "Storm  \n",
            "Looking  \n",
            "Arening o \n",
            "\n",
            "-------------------------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-b41423391dc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m#train the network and get the final hidden state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     hprev_val, loss_val, _ = sess.run([hprev, loss, updated_gradients],\n\u001b[0;32m---> 25\u001b[0;31m                                       feed_dict={inputs: input_vector,targets: target_vector,init_state: hprev_val})\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 958\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    959\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1181\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1182\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}